{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\cscat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import pandas as pd\n",
    "from urllib.request import Request, urlopen\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "from datetime import datetime as dt\n",
    "import os\n",
    "import sys\n",
    "from apis import get_TrackICOAPI\n",
    "import tweepy\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "consumer_key = os.getenv(\"TWITTER_PUBLIC_API\")\n",
    "consumer_secret = os.getenv(\"TWITTER_SECRET_KEY\")\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "addl_stopwords = [',','`', '', 'rt', 'http', 'https', 'RT', 'BTC', 'bitcoin', 'ETH', 'LTC', 'XRP', 'co', 'crypto', 'blockchain', 'cryptocurrency', 'cripto', 'litecoin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_price(df):\n",
    "    '''\n",
    "    Requires df with ticker index\n",
    "    '''\n",
    "    fut_df = pd.DataFrame()\n",
    "    forecast = {}\n",
    "    df = df.fillna(0)\n",
    "    for i in range(len(df)):\n",
    "        try:\n",
    "            ticker = df.index[i]\n",
    "            ohlcv = get_crypto_daily_price(ticker)\n",
    "            fut_df[ticker] = ohlcv['close']\n",
    "            for i in progressbar(range(10), f\"Query Success for {ticker}!, Preparing data for next call: \", 40):\n",
    "                    time.sleep(0.1)\n",
    "\n",
    "        except:\n",
    "            print(f'Unsuccessfull Query for {ticker} :( Setting value to 0')\n",
    "            fut_df[ticker] = 0\n",
    "\n",
    "    for i in df.columns:\n",
    "        try:\n",
    "            model = ARIMA(df[i], order=(6,1,2))\n",
    "            results = model.fit()\n",
    "            forecast[i] = results.forecast(steps=20)[0]\n",
    "            fut_df = pd.DataFrame.from_dict(forecast)\n",
    "        except:\n",
    "            print(f'Passing on {i}')\n",
    "        \n",
    "    return fut_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crypto_daily_price(ticker):\n",
    "    ticker = ticker.upper()\n",
    "    api_key = os.getenv(\"CC_API\")\n",
    "    crypto_df = pd.DataFrame()\n",
    "    url = f\"https://min-api.cryptocompare.com/data/v2/histoday?fsym={ticker}&tsym=USD&allData=true&api_key={api_key}\"\n",
    "    raw_data = read_json(url)\n",
    "    df = pd.DataFrame(raw_data['Data']['Data'])\n",
    "    df['time'] = pd.to_datetime(df['time'],unit='s')\n",
    "    df.set_index(df['time'], inplace=True)\n",
    "    df['close'] = df['close'].astype(float)\n",
    "    df['var'] = df['close'].pct_change()\n",
    "    return df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(url):\n",
    "    request = Request(url)\n",
    "    response = urlopen(request)\n",
    "    data = response.read()\n",
    "    url2 = json.loads(data)\n",
    "    return url2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progressbar(it, prefix=\"\", size=60, file=sys.stdout):\n",
    "    count = len(it)\n",
    "    def show(j):\n",
    "        x = int(size*j/count)\n",
    "        file.write(\"%s[%s%s] %i/%i\\r\" % (prefix, \"#\"*x, \".\"*(size-x), j, count))\n",
    "        file.flush()        \n",
    "    show(0)\n",
    "    for i, item in enumerate(it):\n",
    "        yield item\n",
    "        show(i+1)\n",
    "    file.write(\"\\n\")\n",
    "    file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     country    platform         pre_ico_end  \\\n",
      "Ticker                                                         \n",
      "EZ365   2019-11-01T01:59:00Z    Ethereum 2019-09-22 15:59:00   \n",
      "FUNTO                 Turkey    Ethereum 2019-11-01 01:59:00   \n",
      "TYC                  Germany    Ethereum 2019-10-31 00:00:00   \n",
      "Hawk                   China  Blockchain 2019-08-30 00:00:00   \n",
      "ORX           United Kingdom    Ethereum 2019-11-01 01:59:00   \n",
      "\n",
      "             pre_ico_start rating   status          Name type  \\\n",
      "Ticker                                                          \n",
      "EZ365  2019-09-05 16:00:00    4.6   Closed         EZ365  IEO   \n",
      "FUNTO  2019-11-01 01:59:00    4.1  Ongoing    FunnyToken  ICO   \n",
      "TYC    2019-07-22 00:00:00    5.0  Ongoing        Tycoon  ICO   \n",
      "Hawk   2019-08-15 00:00:00    3.5  Ongoing  Hawk Network  ICO   \n",
      "ORX    2019-11-01 01:59:00    4.8   Closed       Orionix  ICO   \n",
      "\n",
      "                       End               Start          Duration  \\\n",
      "Ticker                                                             \n",
      "EZ365  2019-11-01 01:59:00 2019-09-23 16:00:00  38 days 09:59:00   \n",
      "FUNTO  2019-11-17 00:00:00 2019-08-26 00:00:00  83 days 00:00:00   \n",
      "TYC    2019-11-30 00:00:00 2019-11-01 00:00:00  29 days 00:00:00   \n",
      "Hawk   2019-12-30 00:00:00 2019-09-01 00:00:00 120 days 00:00:00   \n",
      "ORX    2019-11-01 00:00:00 2019-08-01 00:00:00  92 days 00:00:00   \n",
      "\n",
      "            pre_Duration  \n",
      "Ticker                    \n",
      "EZ365   16 days 23:59:00  \n",
      "FUNTO    0 days 00:00:00  \n",
      "TYC    101 days 00:00:00  \n",
      "Hawk    15 days 00:00:00  \n",
      "ORX      0 days 00:00:00  \n"
     ]
    }
   ],
   "source": [
    "track_df = get_TrackICOAPI(2)\n",
    "print(track_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cscat\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: Passing integers to fillna is deprecated, will raise a TypeError in a future version.  To retain the old behavior, pass pd.Timedelta(seconds=n) instead.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsuccessfull Query for EZ365 :( Setting value to 0\n",
      "Unsuccessfull Query for FUNTO :( Setting value to 0\n",
      "Unsuccessfull Query for TYC :( Setting value to 0\n",
      "Unsuccessfull Query for Hawk :( Setting value to 0\n",
      "Unsuccessfull Query for ORX :( Setting value to 0\n",
      "Unsuccessfull Query for DNP :( Setting value to 0\n",
      "Query Success for GT!, Preparing data for next call: [########################################] 10/10\n",
      "Unsuccessfull Query for QI :( Setting value to 0\n",
      "Query Success for MDC!, Preparing data for next call: [########################################] 10/10\n",
      "Unsuccessfull Query for MEQ :( Setting value to 0\n",
      "Unsuccessfull Query for  :( Setting value to 0\n",
      "Unsuccessfull Query for ASR :( Setting value to 0\n",
      "Unsuccessfull Query for SPW :( Setting value to 0\n",
      "Unsuccessfull Query for KTS :( Setting value to 0\n",
      "Unsuccessfull Query for BRIK :( Setting value to 0\n",
      "Unsuccessfull Query for  :( Setting value to 0\n",
      "Unsuccessfull Query for PXP :( Setting value to 0\n",
      "Unsuccessfull Query for MNT :( Setting value to 0\n",
      "Unsuccessfull Query for NCDT :( Setting value to 0\n",
      "Unsuccessfull Query for PWON :( Setting value to 0\n",
      "Unsuccessfull Query for OZO :( Setting value to 0\n",
      "Unsuccessfull Query for AIGO :( Setting value to 0\n",
      "Query Success for FRM!, Preparing data for next call: [########################################] 10/10\n",
      "Unsuccessfull Query for BPLC :( Setting value to 0\n",
      "Unsuccessfull Query for DACX :( Setting value to 0\n",
      "Unsuccessfull Query for GIGJ :( Setting value to 0\n",
      "Unsuccessfull Query for PTR :( Setting value to 0\n",
      "Unsuccessfull Query for CALL :( Setting value to 0\n",
      "Unsuccessfull Query for STAT :( Setting value to 0\n",
      "Unsuccessfull Query for FTC :( Setting value to 0\n",
      "Unsuccessfull Query for MLGC :( Setting value to 0\n",
      "Unsuccessfull Query for 1AI :( Setting value to 0\n",
      "Unsuccessfull Query for SOW :( Setting value to 0\n",
      "Unsuccessfull Query for KAU :( Setting value to 0\n",
      "Unsuccessfull Query for DOM :( Setting value to 0\n",
      "Unsuccessfull Query for TWQ :( Setting value to 0\n",
      "Unsuccessfull Query for UNIS :( Setting value to 0\n",
      "Unsuccessfull Query for FLXC :( Setting value to 0\n",
      "Unsuccessfull Query for SWFT :( Setting value to 0\n",
      "Unsuccessfull Query for PRO :( Setting value to 0\n",
      "Unsuccessfull Query for TAL :( Setting value to 0\n",
      "Unsuccessfull Query for NIXT :( Setting value to 0\n",
      "Unsuccessfull Query for PLAN :( Setting value to 0\n",
      "Unsuccessfull Query for LBRTY :( Setting value to 0\n",
      "Unsuccessfull Query for HNT :( Setting value to 0\n",
      "Unsuccessfull Query for NXX :( Setting value to 0\n",
      "Unsuccessfull Query for STAN :( Setting value to 0\n",
      "Unsuccessfull Query for QRP :( Setting value to 0\n",
      "Passing on country\n",
      "Passing on platform\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cscat\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:215: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "C:\\Users\\cscat\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:215: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "C:\\Users\\cscat\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "C:\\Users\\cscat\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:215: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "C:\\Users\\cscat\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:215: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passing on pre_ico_end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cscat\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "C:\\Users\\cscat\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:215: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "C:\\Users\\cscat\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:215: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passing on pre_ico_start\n",
      "Passing on rating\n",
      "Passing on status\n",
      "Passing on Name\n",
      "Passing on type\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cscat\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "C:\\Users\\cscat\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:215: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "C:\\Users\\cscat\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:215: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passing on End\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cscat\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "C:\\Users\\cscat\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:512: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "C:\\Users\\cscat\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:215: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "C:\\Users\\cscat\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:215: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passing on Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cscat\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "C:\\Users\\cscat\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:215: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "C:\\Users\\cscat\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:215: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passing on Duration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cscat\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:668: RuntimeWarning: invalid value encountered in true_divide\n",
      "  newparams = ((1-np.exp(-params))/(1+np.exp(-params))).copy()\n",
      "C:\\Users\\cscat\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:669: RuntimeWarning: invalid value encountered in true_divide\n",
      "  tmp = ((1-np.exp(-params))/(1+np.exp(-params))).copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passing on pre_Duration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cscat\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n"
     ]
    }
   ],
   "source": [
    "x = forecast_price(track_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twitter_df_score(df, N): \n",
    "    '''\n",
    "    Scores an entire Dataframe of coins based on the last 'N' tweets.  Returns a dataframe of scores with a \n",
    "    '''\n",
    "    scores = []\n",
    "    df2=pd.DataFrame()\n",
    "    num = 0\n",
    "    for name in df.Name:\n",
    "        num += 1\n",
    "        search_term = str(name)\n",
    "        print(f\"Searching and Scoring {search_term}, Tweet #{num} of {len(df)}\")\n",
    "        tweet_df = get_twitter_scores(search_term, N)\n",
    "        score = {name :{\n",
    "                'Compound' : tweet_df.Compound.mean(),\n",
    "                'Positive' : tweet_df.Positive.mean(),\n",
    "                'Negative' : tweet_df.Negative.mean(),\n",
    "                'Neutral' : tweet_df.Neutral.mean(),\n",
    "        }}\n",
    "        scores.append(score)\n",
    "        print(f\"{name} scored\")\n",
    "        for i in progressbar(range(10), \"Waiting for Twitter Rate Limit: \", 40):\n",
    "            time.sleep(1) # any calculation you need\n",
    "    print(f\"Scoring of {len(scores)} tweet concluded, creating dataframe\")\n",
    "    \n",
    "    for item in scores:\n",
    "        df1=pd.DataFrame.from_dict(item).T\n",
    "        df2 = pd.concat([df1,df2], sort = True)\n",
    "#    ndf = pd.concat([df, df2])\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    \"\"\"Tokenizes text.\"\"\"\n",
    "    text = word_tokenize(text)\n",
    "    text = [word.lower() for word in text]\n",
    "    regex = re.compile(\"[^a-zA-Z ]\")\n",
    "    text = [regex.sub('', word) for word in text]\n",
    "    sw = set(stopwords.words('english') + addl_stopwords)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = [lemmatizer.lemmatize(word) for word in text]\n",
    "    clean_text = [word for word in text if word not in sw]\n",
    "    return clean_text\n",
    "\n",
    "def token_count(tokens, N=10):\n",
    "    \"\"\"Returns the top N tokens from the frequency count\"\"\"\n",
    "    return Counter(tokens).most_common(N)\n",
    "\n",
    "\n",
    "# Functions for Twitter\n",
    "\n",
    "\n",
    "def get_tweets_list(topic_of_tweet, num_of_tweets):\n",
    "    '''\n",
    "    Returns a dataframe of the most recent 'N' tweets from Twitter tokenized and counted.\n",
    "    \n",
    "    Arguements: `topic_of_tweet` : str; what hashtag is being searched \n",
    "                'num_of_tweets' : int; how many tweet do you want returned\n",
    "    '''\n",
    "    text,time, word_list, word_count=[],[],[],[]\n",
    "    auth = tweepy.AppAuthHandler(consumer_key, consumer_secret)\n",
    "    api = tweepy.API(auth)\n",
    "    for tweet in tweepy.Cursor(api.search, q=topic_of_tweet, tweet_mode='extended').items(num_of_tweets):\n",
    "        text.append(tweet.full_text),\n",
    "        time.append(tweet.created_at)\n",
    "    tweets_df = pd.DataFrame({'Tweet':text}, index=time)\n",
    "    [word_list.append(tokenizer(text)) for text in tweets_df.Tweet]\n",
    "    tweets_df['Tokens'] = word_list\n",
    "    [word_count.append(token_count(token)) for token in tweets_df.Tokens]\n",
    "    tweets_df['Word_Count'] = word_count\n",
    "    \n",
    "    return tweets_df\n",
    "\n",
    "def twitter_sent_analysis(tweet_df):    \n",
    "    tweet_sentiments, comp, pos, neg, neu = [],[],[],[],[]\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    for tweet in tweet_df.Tweet:\n",
    "        sentiment = analyzer.polarity_scores(tweet),\n",
    "        comp.append(sentiment[0][\"compound\"]),\n",
    "        pos.append(sentiment[0][\"pos\"]),\n",
    "        neg.append(sentiment[0][\"neg\"]),\n",
    "        neu.append(sentiment[0][\"neu\"]),\n",
    "  \n",
    "    tweet_df['Compound'] = comp\n",
    "    tweet_df['Positive'] = pos\n",
    "    tweet_df['Negative'] = neg\n",
    "    tweet_df['Neutral'] = neu\n",
    "\n",
    "    return tweet_df\n",
    "\n",
    "def count(df):\n",
    "    '''\n",
    "    Takes a DataFrame with a \"compund\" column and returns a basic count of positive, neutral, and negative sentiment in a dict format\n",
    "    '''\n",
    "    positive_count, negative_count, neutral_count = 0,0,0\n",
    "    for i in df['Compound']:\n",
    "        if i >= 0.05:\n",
    "            positive_count += 1\n",
    "        elif i <= -0.05:\n",
    "            negative_count += 1\n",
    "        else:\n",
    "            neutral_count += 1\n",
    "    count={\n",
    "        'Positive Tweets': positive_count,\n",
    "        'Neutral Tweets': neutral_count,\n",
    "       'Negavtive Tweets': negative_count\n",
    "    }\n",
    "    return count\n",
    "\n",
    "def get_twitter_scores(topic_of_tweet, num_of_tweets):\n",
    "    df = get_tweets_list(topic_of_tweet, num_of_tweets)\n",
    "    df = twitter_sent_analysis(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/cleandata/track_cmc_merged_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching and Scoring  Ethereum, Tweet #1 of 1010\n",
      " Ethereum scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  XRP, Tweet #2 of 1010\n",
      " XRP scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Tether, Tweet #3 of 1010\n",
      " Tether scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Binance Coin, Tweet #4 of 1010\n",
      " Binance Coin scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  EOS, Tweet #5 of 1010\n",
      " EOS scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Stellar, Tweet #6 of 1010\n",
      " Stellar scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Monero, Tweet #7 of 1010\n",
      " Monero scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Cardano, Tweet #8 of 1010\n",
      " Cardano scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Huobi Token, Tweet #9 of 1010\n",
      " Huobi Token scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Tezos, Tweet #10 of 1010\n",
      " Tezos scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Cosmos, Tweet #11 of 1010\n",
      " Cosmos scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Dash, Tweet #12 of 1010\n",
      " Dash scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Ethereum Classic, Tweet #13 of 1010\n",
      " Ethereum Classic scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  NEM, Tweet #14 of 1010\n",
      " NEM scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Basic Attenti..., Tweet #15 of 1010\n",
      " Basic Attenti... scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Zcash, Tweet #16 of 1010\n",
      " Zcash scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Decred, Tweet #17 of 1010\n",
      " Decred scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Paxos Standard, Tweet #18 of 1010\n",
      " Paxos Standard scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Qtum, Tweet #19 of 1010\n",
      " Qtum scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  HedgeTrade, Tweet #20 of 1010\n",
      " HedgeTrade scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  0x, Tweet #21 of 1010\n",
      " 0x scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Holo, Tweet #22 of 1010\n",
      " Holo scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  V Systems, Tweet #23 of 1010\n",
      " V Systems scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  OmiseGO, Tweet #24 of 1010\n",
      " OmiseGO scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  ZB, Tweet #25 of 1010\n",
      " ZB scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Augur, Tweet #26 of 1010\n",
      " Augur scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Algorand, Tweet #27 of 1010\n",
      " Algorand scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Bytom, Tweet #28 of 1010\n",
      " Bytom scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Komodo, Tweet #29 of 1010\n",
      " Komodo scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Seele, Tweet #30 of 1010\n",
      " Seele scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Lisk, Tweet #31 of 1010\n",
      " Lisk scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Bitcoin Diamond, Tweet #32 of 1010\n",
      " Bitcoin Diamond scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  DxChain Token, Tweet #33 of 1010\n",
      " DxChain Token scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  BitTorrent, Tweet #34 of 1010\n",
      " BitTorrent scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Siacoin, Tweet #35 of 1010\n",
      " Siacoin scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Quant, Tweet #36 of 1010\n",
      " Quant scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  ICON, Tweet #37 of 1010\n",
      " ICON scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Swipe, Tweet #38 of 1010\n",
      " Swipe scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Waves, Tweet #39 of 1010\n",
      " Waves scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  THETA, Tweet #40 of 1010\n",
      " THETA scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  BitShares, Tweet #41 of 1010\n",
      " BitShares scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Bytecoin, Tweet #42 of 1010\n",
      " Bytecoin scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Aeternity, Tweet #43 of 1010\n",
      " Aeternity scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  MCO, Tweet #44 of 1010\n",
      " MCO scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  MaidSafeCoin, Tweet #45 of 1010\n",
      " MaidSafeCoin scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Nexo, Tweet #46 of 1010\n",
      " Nexo scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  iExec RLC, Tweet #47 of 1010\n",
      " iExec RLC scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Zilliqa, Tweet #48 of 1010\n",
      " Zilliqa scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Enjin Coin, Tweet #49 of 1010\n",
      " Enjin Coin scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Energi, Tweet #50 of 1010\n",
      " Energi scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Steem, Tweet #51 of 1010\n",
      " Steem scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Status, Tweet #52 of 1010\n",
      " Status scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Golem, Tweet #53 of 1010\n",
      " Golem scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  UNI COIN, Tweet #54 of 1010\n",
      " UNI COIN scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Newton, Tweet #55 of 1010\n",
      " Newton scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Crypterium, Tweet #56 of 1010\n",
      " Crypterium scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Horizen, Tweet #57 of 1010\n",
      " Horizen scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  GXChain, Tweet #58 of 1010\n",
      " GXChain scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Metaverse ETP, Tweet #59 of 1010\n",
      " Metaverse ETP scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Nash Exchange, Tweet #60 of 1010\n",
      " Nash Exchange scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Electroneum, Tweet #61 of 1010\n",
      " Electroneum scored\n",
      "Waiting for Twitter Rate Limit: [########################################] 10/10\n",
      "Searching and Scoring  Digitex Futures, Tweet #62 of 1010\n"
     ]
    },
    {
     "ename": "TweepError",
     "evalue": "Twitter error response: status code = 429",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTweepError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-9fd24e46d9cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtwitter_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtwitter_df_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-57-4dbde804dcde>\u001b[0m in \u001b[0;36mtwitter_df_score\u001b[1;34m(df, N)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0msearch_term\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Searching and Scoring {search_term}, Tweet #{num} of {len(df)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mtweet_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_twitter_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearch_term\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         score = {name :{\n\u001b[0;32m     14\u001b[0m                 \u001b[1;34m'Compound'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mtweet_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCompound\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-58-6cf86056f6da>\u001b[0m in \u001b[0;36mget_twitter_scores\u001b[1;34m(topic_of_tweet, num_of_tweets)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_twitter_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic_of_tweet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_of_tweets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_tweets_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic_of_tweet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_of_tweets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtwitter_sent_analysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-58-6cf86056f6da>\u001b[0m in \u001b[0;36mget_tweets_list\u001b[1;34m(topic_of_tweet, num_of_tweets)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mauth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAppAuthHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconsumer_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsumer_secret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mapi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAPI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCursor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtopic_of_tweet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtweet_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'extended'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_of_tweets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreated_at\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tweepy\\cursor.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tweepy\\cursor.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_page\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m             \u001b[1;31m# Reached end of current page, get the next page...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tweepy\\cursor.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRawParser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__self__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tweepy\\binder.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    248\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tweepy\\binder.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    231\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mRateLimitError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mTweepError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapi_code\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mapi_error_code\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m             \u001b[1;31m# Parse the response payload\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTweepError\u001b[0m: Twitter error response: status code = 429"
     ]
    }
   ],
   "source": [
    "twitter_df = twitter_df_score(df, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Compound</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tether</th>\n",
       "      <td>0.318450</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.87615</td>\n",
       "      <td>0.12385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XRP</th>\n",
       "      <td>0.125855</td>\n",
       "      <td>0.03695</td>\n",
       "      <td>0.90655</td>\n",
       "      <td>0.05650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ethereum</th>\n",
       "      <td>0.199015</td>\n",
       "      <td>0.01670</td>\n",
       "      <td>0.91795</td>\n",
       "      <td>0.06535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Compound  Negative  Neutral  Positive\n",
       " Tether    0.318450   0.00000  0.87615   0.12385\n",
       " XRP       0.125855   0.03695  0.90655   0.05650\n",
       " Ethereum  0.199015   0.01670  0.91795   0.06535"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
