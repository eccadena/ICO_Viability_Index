{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt at Tweepy\n",
    "#### URL - https://www.pythoncentral.io/introduction-to-tweepy-twitter-for-python/\n",
    "#### credit to Ahmet Novalic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenize import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import os\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status(_api=<tweepy.api.API object at 0x000001EA9AD2F128>, _json={'created_at': 'Mon Nov 11 20:28:45 +0000 2019', 'id': 1193988959703126022, 'id_str': '1193988959703126022', 'text': 'Testing functionality', 'truncated': False, 'entities': {'hashtags': [], 'symbols': [], 'user_mentions': [], 'urls': []}, 'source': '<a href=\"https://www.epiclootsmining.com/\" rel=\"nofollow\">ICO_viability</a>', 'in_reply_to_status_id': None, 'in_reply_to_status_id_str': None, 'in_reply_to_user_id': None, 'in_reply_to_user_id_str': None, 'in_reply_to_screen_name': None, 'user': {'id': 1153340693529714688, 'id_str': '1153340693529714688', 'name': 'Eric Cadena', 'screen_name': 'EricCadena13', 'location': '', 'description': 'Hard worker, educator, and life long learner', 'url': None, 'entities': {'description': {'urls': []}}, 'protected': False, 'followers_count': 1, 'friends_count': 6, 'listed_count': 0, 'created_at': 'Mon Jul 22 16:27:04 +0000 2019', 'favourites_count': 4, 'utc_offset': None, 'time_zone': None, 'geo_enabled': False, 'verified': False, 'statuses_count': 6, 'lang': None, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': 'F5F8FA', 'profile_background_image_url': None, 'profile_background_image_url_https': None, 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/1153341016243658758/JpYo7dls_normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1153341016243658758/JpYo7dls_normal.jpg', 'profile_link_color': '1DA1F2', 'profile_sidebar_border_color': 'C0DEED', 'profile_sidebar_fill_color': 'DDEEF6', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': False, 'default_profile': True, 'default_profile_image': False, 'can_media_tag': True, 'followed_by': False, 'following': False, 'follow_request_sent': False, 'notifications': False, 'translator_type': 'none'}, 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'is_quote_status': False, 'retweet_count': 0, 'favorite_count': 0, 'favorited': False, 'retweeted': False, 'lang': 'en'}, created_at=datetime.datetime(2019, 11, 11, 20, 28, 45), id=1193988959703126022, id_str='1193988959703126022', text='Testing functionality', truncated=False, entities={'hashtags': [], 'symbols': [], 'user_mentions': [], 'urls': []}, source='ICO_viability', source_url='https://www.epiclootsmining.com/', in_reply_to_status_id=None, in_reply_to_status_id_str=None, in_reply_to_user_id=None, in_reply_to_user_id_str=None, in_reply_to_screen_name=None, author=User(_api=<tweepy.api.API object at 0x000001EA9AD2F128>, _json={'id': 1153340693529714688, 'id_str': '1153340693529714688', 'name': 'Eric Cadena', 'screen_name': 'EricCadena13', 'location': '', 'description': 'Hard worker, educator, and life long learner', 'url': None, 'entities': {'description': {'urls': []}}, 'protected': False, 'followers_count': 1, 'friends_count': 6, 'listed_count': 0, 'created_at': 'Mon Jul 22 16:27:04 +0000 2019', 'favourites_count': 4, 'utc_offset': None, 'time_zone': None, 'geo_enabled': False, 'verified': False, 'statuses_count': 6, 'lang': None, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': 'F5F8FA', 'profile_background_image_url': None, 'profile_background_image_url_https': None, 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/1153341016243658758/JpYo7dls_normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1153341016243658758/JpYo7dls_normal.jpg', 'profile_link_color': '1DA1F2', 'profile_sidebar_border_color': 'C0DEED', 'profile_sidebar_fill_color': 'DDEEF6', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': False, 'default_profile': True, 'default_profile_image': False, 'can_media_tag': True, 'followed_by': False, 'following': False, 'follow_request_sent': False, 'notifications': False, 'translator_type': 'none'}, id=1153340693529714688, id_str='1153340693529714688', name='Eric Cadena', screen_name='EricCadena13', location='', description='Hard worker, educator, and life long learner', url=None, entities={'description': {'urls': []}}, protected=False, followers_count=1, friends_count=6, listed_count=0, created_at=datetime.datetime(2019, 7, 22, 16, 27, 4), favourites_count=4, utc_offset=None, time_zone=None, geo_enabled=False, verified=False, statuses_count=6, lang=None, contributors_enabled=False, is_translator=False, is_translation_enabled=False, profile_background_color='F5F8FA', profile_background_image_url=None, profile_background_image_url_https=None, profile_background_tile=False, profile_image_url='http://pbs.twimg.com/profile_images/1153341016243658758/JpYo7dls_normal.jpg', profile_image_url_https='https://pbs.twimg.com/profile_images/1153341016243658758/JpYo7dls_normal.jpg', profile_link_color='1DA1F2', profile_sidebar_border_color='C0DEED', profile_sidebar_fill_color='DDEEF6', profile_text_color='333333', profile_use_background_image=True, has_extended_profile=False, default_profile=True, default_profile_image=False, can_media_tag=True, followed_by=False, following=False, follow_request_sent=False, notifications=False, translator_type='none'), user=User(_api=<tweepy.api.API object at 0x000001EA9AD2F128>, _json={'id': 1153340693529714688, 'id_str': '1153340693529714688', 'name': 'Eric Cadena', 'screen_name': 'EricCadena13', 'location': '', 'description': 'Hard worker, educator, and life long learner', 'url': None, 'entities': {'description': {'urls': []}}, 'protected': False, 'followers_count': 1, 'friends_count': 6, 'listed_count': 0, 'created_at': 'Mon Jul 22 16:27:04 +0000 2019', 'favourites_count': 4, 'utc_offset': None, 'time_zone': None, 'geo_enabled': False, 'verified': False, 'statuses_count': 6, 'lang': None, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': 'F5F8FA', 'profile_background_image_url': None, 'profile_background_image_url_https': None, 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/1153341016243658758/JpYo7dls_normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1153341016243658758/JpYo7dls_normal.jpg', 'profile_link_color': '1DA1F2', 'profile_sidebar_border_color': 'C0DEED', 'profile_sidebar_fill_color': 'DDEEF6', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': False, 'default_profile': True, 'default_profile_image': False, 'can_media_tag': True, 'followed_by': False, 'following': False, 'follow_request_sent': False, 'notifications': False, 'translator_type': 'none'}, id=1153340693529714688, id_str='1153340693529714688', name='Eric Cadena', screen_name='EricCadena13', location='', description='Hard worker, educator, and life long learner', url=None, entities={'description': {'urls': []}}, protected=False, followers_count=1, friends_count=6, listed_count=0, created_at=datetime.datetime(2019, 7, 22, 16, 27, 4), favourites_count=4, utc_offset=None, time_zone=None, geo_enabled=False, verified=False, statuses_count=6, lang=None, contributors_enabled=False, is_translator=False, is_translation_enabled=False, profile_background_color='F5F8FA', profile_background_image_url=None, profile_background_image_url_https=None, profile_background_tile=False, profile_image_url='http://pbs.twimg.com/profile_images/1153341016243658758/JpYo7dls_normal.jpg', profile_image_url_https='https://pbs.twimg.com/profile_images/1153341016243658758/JpYo7dls_normal.jpg', profile_link_color='1DA1F2', profile_sidebar_border_color='C0DEED', profile_sidebar_fill_color='DDEEF6', profile_text_color='333333', profile_use_background_image=True, has_extended_profile=False, default_profile=True, default_profile_image=False, can_media_tag=True, followed_by=False, following=False, follow_request_sent=False, notifications=False, translator_type='none'), geo=None, coordinates=None, place=None, contributors=None, is_quote_status=False, retweet_count=0, favorite_count=0, favorited=False, retweeted=False, lang='en')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Consumer keys and access tokens, used for OAuth\n",
    "consumer_key = os.getenv(\"TWITTER_CONSUMER_API\")\n",
    "consumer_secret = os.getenv(\"TWITTER_CONSUMER_SECRET_API\")\n",
    "access_token = os.getenv(\"TWITTER_ACCESS_TOKEN\")\n",
    "access_token_secret = os.getenv(\"TWITTER_ACCESS_SECRET_TOKEN\")\n",
    " \n",
    "# OAuth process, using the keys and tokens\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    " \n",
    "# Creation of the actual interface, using authentication\n",
    "api = tweepy.API(auth)\n",
    " \n",
    "# Sample method, used to update a status\n",
    "api.update_status('Testing functionality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Eric Cadena\n",
      "Location: \n",
      "Friends: 6\n"
     ]
    }
   ],
   "source": [
    "user = api.me()\n",
    " \n",
    "print('Name: ' + user.name)\n",
    "print('Location: ' + user.location)\n",
    "print('Friends: ' + str(user.friends_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Christian's Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets_list(topic_of_tweet, num_of_tweets):\n",
    "    '''\n",
    "    Returns a dataframe of the most recent 'N' tweets from Twitter tokenized and counted.\n",
    "\n",
    "    Arguements: `topic_of_tweet` : str; what hashtag is being searched\n",
    "                'num_of_tweets' : int; how many tweet do you want returned\n",
    "    '''\n",
    "    text,time, word_list, word_count=[],[],[],[]\n",
    "    auth = tweepy.AppAuthHandler(consumer_key, consumer_secret)\n",
    "    api = tweepy.API(auth)\n",
    "    for tweet in tweepy.Cursor(api.search, q=topic_of_tweet, tweet_mode='extended').items(num_of_tweets):\n",
    "        text.append(tweet.full_text),\n",
    "        time.append(tweet.created_at)\n",
    "    tweets_df = pd.DataFrame({'Tweet':text}, index=time)\n",
    "    [word_list.append(tokenizer(text)) for text in tweets_df.Tweet] #tokenize \n",
    "    tweets_df['Tokens'] = word_list\n",
    "    [word_count.append(token_count(token)) for token in tweets_df.Tokens]\n",
    "    tweets_df['Word_Count'] = word_count\n",
    "\n",
    "    return tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-a5956eb00b5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_tweets_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"#BTC\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-25-8d30d3967a12>\u001b[0m in \u001b[0;36mget_tweets_list\u001b[1;34m(topic_of_tweet, num_of_tweets)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreated_at\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mtweets_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Tweet'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[1;33m[\u001b[0m\u001b[0mword_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweets_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTweet\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#tokenize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mtweets_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Tokens'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;33m[\u001b[0m\u001b[0mword_count\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweets_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTokens\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-8d30d3967a12>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreated_at\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mtweets_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Tweet'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[1;33m[\u001b[0m\u001b[0mword_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweets_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTweet\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#tokenize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mtweets_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Tokens'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;33m[\u001b[0m\u001b[0mword_count\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweets_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTokens\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "get_tweets_list(\"#BTC\",10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication OK\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    api.verify_credentials()\n",
    "    print(\"Authentication OK\")\n",
    "except:\n",
    "    print(\"Error during authentication\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(search_term, number_recent_public_posts):\n",
    "    \n",
    "    for tweet in api.search(q={search_term}, lang=\"en\", rpp={number_recent_public_posts}):\n",
    "        print(f\"{tweet.user.name}:{tweet.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yamato3908:RT @churi_mon: 🌏EVEO 6th country listing🌏\n",
      "\n",
      "Sleeping Giant Cryptocurrency No.1 exchange\n",
      "\n",
      "■Date■Nov.22 2019 12UTC.(PM9 JST)\n",
      "■Pair■BTC/ETH/USD…\n",
      "Android Jobs:Project Manager to manage through deployments (Web App, Android Mobile App, iOS Mobile App) - Fixed USD each w - https://t.co/xvJUD3AOFA\n",
      "Danilo Herdy:As of November 11, 2019 at 06:50PM, 1 USD equals 4.1376 BRL. #cambio\n",
      "Daniel Duarte Jevaux:As of November 10, 2019 at 03:50PM, 1 USD equals 4.1376 BRL.\n",
      "FOREX Solutions:As of November 11, 2019 at 08:50PM, 1 GBP equals 1.2875 USD. #Forex #GBPUSD #RT\n",
      "Supreme Click:Nike Air Max 90 NRG\n",
      "Color: Desert Sand/Black-Desert Dust\n",
      "Style Code: CI5646-001\n",
      "Release Date: November 15, 2019\n",
      "Pri… https://t.co/xbIotrxnyd\n",
      "Tomas Zdrazil:The amount of #ethereum locked in #decentralized financial applications, dubbed as #DeFi has reached an all time hi… https://t.co/GC0okvQcwk\n",
      "Aaron Bowen  }~MaddogBowen~{:I just raised $20.00 USD for local @CMNHospitals thru #EXTRALIFE. Donate today &amp; help me reach my goal: https://t.co/K5Xx7eYv32\n",
      "Jeremy Zaplatosch:'01 Skyline R34 GT-R. 132k km/82k mi. 62k USD.\n",
      ".\n",
      "jeremy@zapautoexport.com. Everything you need. Auction info, shipp… https://t.co/dT5wFzBYav\n",
      "We ❤️ Xbox:Merry Mint Pick Axe Code Unused Fortnite Pickaxe Card IN HAND #PS4, #Xbox, PC #eBay\n",
      "⏰ Ends in 5h\n",
      "💲 Last Price USD 1… https://t.co/X3pgXoiWTW\n",
      "John Hablitz:RT @SeanMonaghanSM: If anyone is curious what the Chinese 3rd division pays a head coach: (from a club that is now hiring)\n",
      "\n",
      "- $4,300 USD a…\n",
      "CREATE:Wish I paid attention to $LTC... My paper trade in USD nailed the bottom.\n",
      "\n",
      "$BTC pair however looks like it wont giv… https://t.co/HgeDjEL2NE\n",
      "IM NOT BISEXUAL IM BI MYSELF | I is AdorB:RT @beetljuuc: PLES LIKE/RETWEET, The algorithm really has been kicking me lately, these are currently my only income, feel free to DM me i…\n",
      "Nic-m-lyc:NEW AUCTION FOR A NEW CHARACTER IN HERE! The bid starts at 5 usd! Good luck UwU https://t.co/WVIQFyE0AH https://t.co/jZU9IV3NE1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(get_tweets('USD', 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'full_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-363b718b96c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'full_text'"
     ]
    }
   ],
   "source": [
    "test.full_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geeks for Geeks Sentiment analysis https://www.geeksforgeeks.org/twitter-sentiment-analysis-using-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tweepy import OAuthHandler \n",
    "from textblob import TextBlob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-54-ed042e86b1db>, line 34)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-54-ed042e86b1db>\"\u001b[1;36m, line \u001b[1;32m34\u001b[0m\n\u001b[1;33m    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])\u001b[0m\n\u001b[1;37m                                                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "#VS CODE For reference. Code is indepth\n",
    "\n",
    "class TwitterClient(object): \n",
    "    ''' \n",
    "    Generic Twitter Class for sentiment analysis. \n",
    "    '''\n",
    "    def __init__(self): \n",
    "        ''' \n",
    "        Class constructor or initialization method. \n",
    "        '''\n",
    "        # keys and tokens from the Twitter Dev Console \n",
    "        consumer_key = 'XXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "        consumer_secret = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "        access_token = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "        access_token_secret = 'XXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "  \n",
    "        # attempt authentication \n",
    "        try: \n",
    "            # create OAuthHandler object \n",
    "            self.auth = OAuthHandler(consumer_key, consumer_secret) \n",
    "            # set access token and secret \n",
    "            self.auth.set_access_token(access_token, access_token_secret) \n",
    "            # create tweepy API object to fetch tweets \n",
    "            self.api = tweepy.API(self.auth) \n",
    "        except: \n",
    "            print(\"Error: Authentication Failed\") \n",
    "### usual authentication steps ------------------------\n",
    "\n",
    "    def clean_tweet(self, tweet): \n",
    "        ''' \n",
    "        Utility function to clean tweet text by removing links, special characters \n",
    "        using simple regex statements. \n",
    "        '''\n",
    "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t]) \n",
    "                                    |(\\w+:\\/\\/\\S+)\", \" \", tweet).split()) \n",
    "### using regex to clean tweets --------------------------\n",
    "                               \n",
    "    def get_tweet_sentiment(self, tweet): \n",
    "        ''' \n",
    "        Utility function to classify sentiment of passed tweet \n",
    "        using textblob's sentiment method \n",
    "        '''\n",
    "        # create TextBlob object of passed tweet text \n",
    "        analysis = TextBlob(self.clean_tweet(tweet)) \n",
    "        # set sentiment \n",
    "        if analysis.sentiment.polarity > 0: \n",
    "            return 'positive'\n",
    "        elif analysis.sentiment.polarity == 0: \n",
    "            return 'neutral'\n",
    "        else: \n",
    "            return 'negative'\n",
    "\n",
    "#cleaning the tweet then passing it to a sentiment analysis function, polarity.\n",
    "                               \n",
    "    def get_tweets(self, query, count = 10): \n",
    "        ''' \n",
    "        Main function to fetch tweets and parse them. \n",
    "        '''\n",
    "        # empty list to store parsed tweets \n",
    "        tweets = [] \n",
    "  \n",
    "        try: \n",
    "            # call twitter api to fetch tweets \n",
    "            fetched_tweets = self.api.search(q = query, count = count) \n",
    "  \n",
    "            # parsing tweets one by one \n",
    "            for tweet in fetched_tweets: \n",
    "                # empty dictionary to store required params of a tweet \n",
    "                parsed_tweet = {} \n",
    "  \n",
    "                # saving text of tweet \n",
    "                parsed_tweet['text'] = tweet.text \n",
    "                # saving sentiment of tweet \n",
    "                parsed_tweet['sentiment'] = self.get_tweet_sentiment(tweet.text) \n",
    "  \n",
    "                # appending parsed tweet to tweets list \n",
    "                if tweet.retweet_count > 0: \n",
    "                    # if tweet has retweets, ensure that it is appended only once \n",
    "                    if parsed_tweet not in tweets: \n",
    "                        tweets.append(parsed_tweet) \n",
    "                else: \n",
    "                    tweets.append(parsed_tweet) \n",
    "  \n",
    "            # return parsed tweets \n",
    "            return tweets \n",
    "  \n",
    "        except tweepy.TweepError as e: \n",
    "            # print error (if any) \n",
    "            print(\"Error : \" + str(e)) \n",
    "  \n",
    "def main(): \n",
    "    # creating object of TwitterClient Class \n",
    "    api = TwitterClient() \n",
    "    # calling function to get tweets \n",
    "    tweets = api.get_tweets(query = 'Donald Trump', count = 200) \n",
    "  \n",
    "    # picking positive tweets from tweets \n",
    "    ptweets = [tweet for tweet in tweets if tweet['sentiment'] == 'positive'] \n",
    "    # percentage of positive tweets \n",
    "    print(\"Positive tweets percentage: {} %\".format(100*len(ptweets)/len(tweets))) \n",
    "    # picking negative tweets from tweets \n",
    "    ntweets = [tweet for tweet in tweets if tweet['sentiment'] == 'negative'] \n",
    "    # percentage of negative tweets \n",
    "    print(\"Negative tweets percentage: {} %\".format(100*len(ntweets)/len(tweets))) \n",
    "    # percentage of neutral tweets \n",
    "    print(\"Neutral tweets percentage: {} % \\ \n",
    "        \".format(100*len(tweets - ntweets - ptweets)/len(tweets))) \n",
    "  \n",
    "    # printing first 5 positive tweets \n",
    "    print(\"\\n\\nPositive tweets:\") \n",
    "    for tweet in ptweets[:10]: \n",
    "        print(tweet['text']) \n",
    "  \n",
    "    # printing first 5 negative tweets \n",
    "    print(\"\\n\\nNegative tweets:\") \n",
    "    for tweet in ntweets[:10]: \n",
    "        print(tweet['text']) \n",
    "  \n",
    "# if __name__ == \"__main__\": \n",
    "#     # calling main function \n",
    "#     main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
